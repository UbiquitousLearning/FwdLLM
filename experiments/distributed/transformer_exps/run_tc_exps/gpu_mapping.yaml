# Please check "GPU_MAPPING.md" to see how to define the topology
# You can define a cluster containing multiple GPUs within multiple machines by defining `gpu_mapping.yaml` as follows:

# config_cluster0:
#     host_name_node0: [num_of_processes_on_GPU0, num_of_processes_on_GPU1, num_of_processes_on_GPU2, num_of_processes_on_GPU3, ..., num_of_processes_on_GPU_n]
#     host_name_node1: [num_of_processes_on_GPU0, num_of_processes_on_GPU1, num_of_processes_on_GPU2, num_of_processes_on_GPU3, ..., num_of_processes_on_GPU_n]
#     host_name_node_m: [num_of_processes_on_GPU0, num_of_processes_on_GPU1, num_of_processes_on_GPU2, num_of_processes_on_GPU3, ..., num_of_processes_on_GPU_n]


mapping_lambda-server2:
    lambda-server2: [0, 0, 0, 0, 3, 2, 3, 3]

# this is used for 10 clients and 1 server training within a single machine which has 4 GPUs
mapping_default:
    ChaoyangHe-GPU-RTX2080Tix4: [2, 1, 1, 1]

# this is used for 4 clients and 1 server training within a single machine which has 4 GPUs
mapping_config1_5:
    host1: [2, 1, 1, 1]

# this is used for 10 clients and 1 server training within a single machine which has 4 GPUs
mapping_config2_11:
    host1: [3, 3, 3, 2]

# this is used for 10 clients and 1 server training within a single machine which has 8 GPUs
mapping_config3_11:
    host1: [2, 2, 2, 1, 1, 1, 1, 1]

# this is used for 4 clients and 1 server training within a single machine which has 8 GPUs, but you hope to skip the GPU device ID.
mapping_config4_5:
    host1: [1, 0, 0, 1, 1, 0, 1, 1]

# this is used for 4 clients and 1 server training using 6 machines, each machine has 2 GPUs inside, but you hope to use the second GPU.
mapping_ink-ron:
    ink-ron: [1, 2, 2, 2, 2, 2]

mapping_ink-lucy:
    ink-lucy: [2, 3, 3, 3]

mapping_a100:
    g1lmd2: [2, 2, 2, 1, 1, 1, 1, 1]

mapping_a100_2:
    g1lmd2: [2, 2, 2, 1, 1, 1, 1, 1]
mapping_myMap:
    host: [2, 0, 0, 0, 0, 0, 0, 0]